# -*- coding: utf-8 -*-
'''
    Python Mapper script
    Generated by the Python Mapper GUI
'''

import mapper
import numpy as np
import matplotlib.pyplot as plt
import os
from handledata.modify_data import sample
from sklearn import preprocessing

'''
    Step 1: Input

'''
file_dir = '/Users/gy/Desktop/paperPicture/train/temp/train1'
out_dir = '/Users/gy/Desktop/paperPicture/Aug11topology/filterpic'

def generatedata(filename):
    data = np.loadtxt(str(filename), delimiter=',', dtype=np.float)
    sampledata01 = sample(data, 0.5)
    #sampledata02 = sample(data, 0.5)
    #sampledata03 = sample(data, 0.5)
    #sampledata04 = sample(data, 0.5)
    sampledata1 = sample(data, 0.6)
    sampledata10 = sample(data, 0.65)
    sampledata2 = sample(data, 0.7)
    sampledata20 = sample(data, 0.75)
    sampledata3 = sample(data, 0.8)
    sampledata30 = sample(data, 0.85)
    sampledata4 = sample(data, 0.9)
    sampledata40 = sample(data, 0.9)
    #sampledata4 = sample(data, 0.95)
    #, sampledata0, sampledata1, sampledata2, sampledata3, sampledata4
    #, sampledata01, sampledata1,sampledata10, sampledata2,sampledata20, sampledata3,sampledata30, sampledata4, sampledata40
    return [data]

def generate(data, outpath, ecc, inter, over, gap, check, partion, imgid):

    # Preprocessing
    point_labels = None
    mask = None
    crop = mapper.crop
    # Custom preprocessing code

    # End custom preprocessing code
    data, point_labels = mapper.mask_data(data, mask, point_labels)
    '''
        Step 2: Metric
    '''
    intrinsic_metric = False
    if intrinsic_metric:
        is_vector_data = data.ndim != 1
        if is_vector_data:
            metric = 'Euclidean'
            if metric != 'Euclidean':
                raise ValueError('Not implemented')
        data = mapper.metric.intrinsic_metric(data, k=1, eps=1.0)
    is_vector_data = data.ndim != 1
    '''
        Step 3: Filter function
    '''
    if is_vector_data:
        metricpar = {'metric': 'euclidean'}
        #f = mapper.filters.distance_to_measure(data, k=ecc, metricpar=metricpar, callback=None)
        #f = mapper.filters.eccentricity(data, exponent=ecc,  metricpar=metricpar, callback=None)
        f = mapper.filters.kNN_distance(data, k=ecc, metricpar=metricpar, callback=None)
        #f = mapper.filters.dm_eigenvector(data, k=ecc, mean_center=True, metricpar=metricpar)

        #### ##############
        #sort, how many data in one interval nf,
        b = f.max() - f.min()
        n = 50
        nf = []
        for i in range(n):
            temp1 = np.where(f < (f.min() + i * b / n))[0]
            temp2 = np.where(f<(f.min() + (i+1) *b /n))[0]
            nf.append(temp2.shape[0]-temp1.shape[0])

        plt.bar(range(n), height=nf)
        plt.xticks((0, n), (f.min(), f.max()))

        #plt.ylabel('filter value')
        #plt.savefig(outpath)
        plt.show()
        if check > 0:
            min_f = min(f)
            max_f = max(f)
            m1 = min_f + (max_f - min_f) / 4
            m2 = max_f - (max_f - min_f) / check

            index = np.where(f<m2)
            index = index[0]
            index1 = np.where(f >m1)
            index1 = index1[0]

            #f1 = np.extract(f > m1, f)
            #f2 = np.extract(f > m2, f)
            real_n = index.shape[0]
            pick_ed = f.shape[0] - real_n
            if (pick_ed < int(partion * f.shape[0])):

                data_real = []
                for i in index1:

                    data_real.append(data[i])
                data_real = np.array(data_real)


                data = data_real

                f = mapper.filters.distance_to_measure(data, k=ecc, metricpar=metricpar, callback=None)
                #f = mapper.filters.eccentricity(data, exponent=ecc, metricpar=metricpar, callback=None)
                #f = mapper.filters.kNN_distance(data, k=2, metricpar=metricpar, callback=None)


    else:
        f = mapper.filters.eccentricity(data,
                                        exponent=ecc)
    # Filter transformation
    mask = None
    crop = mapper.crop
    # Custom filter transformation

    # End custom filter transformation
    '''
        Step 4: Mapper parameters
    '''
    cover = mapper.cover.cube_cover_primitive(intervals=inter, overlap=over)
    cluster = mapper.complete_linkage()
    if not is_vector_data:
        metricpar = {}
    mapper_output = mapper.mapper(data, f,
                                  cover=cover,
                                  cluster=cluster,
                                  point_labels=point_labels,
                                  cutoff=None,
                                  metricpar=metricpar)
    cutoff = mapper.cutoff.first_gap(gap=gap)
    mapper_output.cutoff(cutoff, f, cover=cover, simple=False)
    mapper_output.draw_scale_graph()
    #plt.savefig('scale_graph.pdf')

    '''
        Step 5: Display parameters
    '''
    # Node coloring

    nodes = mapper_output.nodes
    node_color = None
    point_color = None
    name = 'custom scheme'
    # Custom node coloring
    #point_color=data[:, 0]
    # End custom node coloring
    #node_color = mapper_output.postprocess_node_color(node_color, point_color, point_labels)
    minsizes = []
    #mapper_output.draw_2D(minsizes=minsizes,node_color=node_color,node_color_scheme=name, legend=False)
    #plt.savefig(outpath)
    #plt.show()




if __name__ == "__main__":
    #distance 3, 11, 50, 0.04
    #distance [3, 15, 50, 0.04], [[3, 14, 50, 0.04]],[[3, 20, 50, 0.06]], ***[[3, 10, 50, 0.04]], ***[[4, 14, 50, 0.05]], ***[[4, 14, 50, 0.04]]
    #distance [[3, 20, 50, 0.05]]
    #for training combine distance [[40, 11, 50, 0.06]]
    #knn [[3, 20, 50, 0.07]]
    #average cluster ecc:[[0.2, 12, 50, 0.1]] for 0 to have circle
    #average cluster ecc:[[0.2, 11, 50, 0.08]] the best for 0 to have fircle till now
    params = np.array([[2, 45, 30, 0.2]])
    for path in os.listdir(file_dir):
        imgid = 0
        if path != '.DS_Store':
            for param in params:
                filepath = os.path.join('%s/%s' % (file_dir, path))
                s = path.replace('.csv', '')
                outpath = os.path.join('%s/%s-%d-%d-%d-%.2f.pdf' % (out_dir, s, param[0],int(param[1]),int(param[2]),param[3]))

                #if os.path.exists(outpath) == :
                datalis = generatedata(filepath)
                print outpath
                # 0modify 0.5, 0.6 some be useful
                for data in datalis:
                    imgid += 1
                    generate(data, outpath, int(param[0]), int(param[1]), param[2], param[3], check=0, partion=0.1,
                             imgid=imgid)


                    #效果并没有想象中的好，修改%80就检测不出来，可能是参数原因，明天在修改，还有就是小部分修改还是和假的是一样的。这里看看能不能检测出来。
# 还有要不要考虑filter值非常小的一部分有值，但是大部分的点都在最大值附近的情况，最好还是考虑一下，明天具体在看看。
#现在从70%开始可以判断了 ecc：[[2, 20, 50, 0.3]] 切分参数：6， 8／10
#对于大部分窜改1的还要找参数
#dis 3 22 50 0.08  3 20 50 0.06 切分参数3 0.8 这个不行[[3, 22, 50, 0.07]]），

#ecc 5 18 50 0.08

#最终结果参数：
#修改0的ecc：[[2, 20, 50, 0.3]] 切分参数：6， 8／10
#修改1的dis：[[3, 10, 50, 0.04]] 切分参数：4， 0.8
#所有的切分参数应该都是可以改变的，看效果

#best till now knn [[2, 18, 38, 0.03]]
#dis [2, 10, 50, 0.04]
#dis [2, 8, 50, 0.04]
#dis [3, 8, 50, 0.04] cutoff average
#暂定用[3, 8, 50, 0.03], [3, 7, 50, 0.02], [3, 6, 50, 0.02], [3, 6, 48, 0.03], [3, 6, 48, 0.02]


#knn[[18, 45, 30, 0.2]]最终参数